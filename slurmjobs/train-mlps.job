#!/bin/bash

#SBATCH --output=./slurmjobs/slurmlogs/%j.out
#SBATCH --gres=gpu:gtx1060:1
#SBATCH --cpus-per-task=3
#SBATCH --threads-per-core=1
#SBATCH --mem-per-gpu=16G
#SBATCH --job-name=train-resnet-18-1x

export CUDA_DEVICE_ORDER="PCI_BUS_ID"
export CUDA_VISIBLE_DEVICES=$(echo $SLURM_JOB_GPUS | cut -d "," -f1)

source venv/bin/activate
python -c \
"\
import os; \
import torch; \
import psutil; \
print('-------------------SBATCH STATS-------------------'); \
print(f'Total CPU cores:      {os.cpu_count()}'); \
print(f'Visible CPU cores:    {len(os.sched_getaffinity(0))}'); \
print(f'Visible GPUs:         {torch.cuda.get_device_name(torch.cuda.current_device())}'); \
print('-'*50)
"

python src/train.py --dataset MNIST --model MLP --size 4 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 4 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
python src/train.py --dataset MNIST --model MLP --size 5 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 5 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
python src/train.py --dataset MNIST --model MLP --size 6 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 6 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
python src/train.py --dataset MNIST --model MLP --size 7 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 7 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
python src/train.py --dataset MNIST --model MLP --size 8 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 8 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
python src/train.py --dataset MNIST --model MLP --size 9 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 9 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
python src/train.py --dataset MNIST --model MLP --size 10 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant a -wandb -test
python src/train.py --dataset MNIST --model MLP --size 10 --width 1 --lr 0.2 --weight_decay 0 --epochs 100 --variant b -wandb -test
