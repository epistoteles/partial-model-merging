-------------------SBATCH STATS-------------------
Total CPU cores:      6
Visible CPU cores:    3
Visible GPUs:         NVIDIA GeForce RTX 3060
--------------------------------------------------
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=1.2, epochs=100, lr=0.08, weight_decay=0.0005, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231118_165914-vi1imqhy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sky-144
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/vi1imqhy
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:12:50
📥 Accuracies and losses saved for CIFAR10-VGG11-bn-1.2x-a
train_acc    0.99996
train_loss   0.0010111716063693167
test_acc     0.9176
test_loss    0.3314224720001221
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb:      test_loss █▅▄▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████████
wandb:     train_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9176
wandb:      test_loss 0.33142
wandb: train_accuracy 0.99976
wandb:     train_loss 0.00146
wandb: 
wandb: 🚀 View run wandering-sky-144 at: https://wandb.ai/epistoteles/partial-model-merging/runs/vi1imqhy
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231118_165914-vi1imqhy/logs
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=1.2, epochs=100, lr=0.08, weight_decay=0.0005, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231118_171239-zvdxz0lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-field-145
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/zvdxz0lx
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:12:51
📥 Accuracies and losses saved for CIFAR10-VGG11-bn-1.2x-b
train_acc    0.99998
train_loss   0.0009134501020889729
test_acc     0.9185
test_loss    0.3243684768676758
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:      test_loss █▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb:     train_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9185
wandb:      test_loss 0.32437
wandb: train_accuracy 0.99992
wandb:     train_loss 0.0015
wandb: 
wandb: 🚀 View run swept-field-145 at: https://wandb.ai/epistoteles/partial-model-merging/runs/zvdxz0lx
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231118_171239-zvdxz0lx/logs
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=1.3, epochs=100, lr=0.08, weight_decay=0.0005, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231118_172604-zf0ur7he
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-cherry-146
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/zf0ur7he
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:14:24
📥 Accuracies and losses saved for CIFAR10-VGG11-bn-1.3x-a
train_acc    0.99998
train_loss   0.0008949759078677743
test_acc     0.9176
test_loss    0.3319029599428177
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄▄▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:      test_loss █▅▅▃▃▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb:     train_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9176
wandb:      test_loss 0.3319
wandb: train_accuracy 0.9999
wandb:     train_loss 0.00146
wandb: 
wandb: 🚀 View run polished-cherry-146 at: https://wandb.ai/epistoteles/partial-model-merging/runs/zf0ur7he
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231118_172604-zf0ur7he/logs
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=1.3, epochs=100, lr=0.08, weight_decay=0.0005, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231118_174104-yxv0dl5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-planet-147
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/yxv0dl5c
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:14:25
📥 Accuracies and losses saved for CIFAR10-VGG11-bn-1.3x-b
train_acc    0.99996
train_loss   0.0009253905469086021
test_acc     0.919
test_loss    0.33135421872138976
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:      test_loss █▆▃▂▃▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb:     train_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.919
wandb:      test_loss 0.33135
wandb: train_accuracy 0.99984
wandb:     train_loss 0.00153
wandb: 
wandb: 🚀 View run frosty-planet-147 at: https://wandb.ai/epistoteles/partial-model-merging/runs/yxv0dl5c
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231118_174104-yxv0dl5c/logs
