-------------------SBATCH STATS-------------------
Total CPU cores:      6
Visible CPU cores:    3
Visible GPUs:         NVIDIA GeForce RTX 3060
--------------------------------------------------
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=True, width=0.5,
epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, test=True, 
checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_153527-l00qd2gn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-music-341
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/l00qd2gn
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:37
📥 Accuracies and losses saved for MNIST-MLP3-bn-0.5x-a
train_acc    0.9999833333333333
train_loss   0.0004178138638962992
test_acc     0.9902
test_loss    0.031082029454410076
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▅▇▇▇▇▇▇████████████████████████████████
wandb:      test_loss █▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇▇█████████████████████████████████████
wandb:     train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9902
wandb:      test_loss 0.03108
wandb: train_accuracy 0.99993
wandb:     train_loss 0.00096
wandb: 
wandb: 🚀 View run neat-music-341 at: https://wandb.ai/epistoteles/partial-model-merging/runs/l00qd2gn
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231127_153527-l00qd2gn/logs
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=True, width=0.5,
epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, test=True, 
checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_154236-vl1jgt9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-haze-343
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/vl1jgt9v
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:18
📥 Accuracies and losses saved for MNIST-MLP3-bn-0.5x-b
train_acc    1.0
train_loss   0.00037473471117361137
test_acc     0.9904
test_loss    0.032681679166853425
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇▇▇▇▇█████████████████████████████████
wandb:      test_loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇▇█████████████████████████████████████
wandb:     train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9904
wandb:      test_loss 0.03268
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00095
wandb: 
wandb: 🚀 View run brisk-haze-343 at: https://wandb.ai/epistoteles/partial-model-merging/runs/vl1jgt9v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231127_154236-vl1jgt9v/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=True, width=0.5,
epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, test=True, 
checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_154924-3fpdv7ac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-spaceship-345
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/3fpdv7ac
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:35
📥 Accuracies and losses saved for MNIST-MLP4-bn-0.5x-a
train_acc    1.0
train_loss   0.00014306792315134468
test_acc     0.9915
test_loss    0.03293006382882595
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇▇▇▇▇▇████████████████████████████████
wandb:      test_loss █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇▇█████████████████████████████████████
wandb:     train_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9915
wandb:      test_loss 0.03293
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00047
wandb: 
wandb: 🚀 View run neat-spaceship-345 at: https://wandb.ai/epistoteles/partial-model-merging/runs/3fpdv7ac
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231127_154924-3fpdv7ac/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=True, width=0.5,
epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, test=True, 
checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_155629-efxmice5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-glitter-347
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/efxmice5
