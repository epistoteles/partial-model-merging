-------------------SBATCH STATS-------------------
Total CPU cores:      6
Visible CPU cores:    4
Visible GPUs:         NVIDIA GeForce RTX 3060
--------------------------------------------------
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=0.5, epochs=100, lr=0.08, weight_decay=0.0005, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231110_171503-jozzqxml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-hill-136
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/jozzqxml
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:02:50
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▃▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb:      test_loss █▆▄▃▃▂▂▂▂▂▁▂▁▂▂▂▂▁▂▂▁▂▂▂▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:     train_loss █▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9021
wandb:      test_loss 0.40008
wandb: train_accuracy 0.9983
wandb:     train_loss 0.00806
wandb: 
wandb: 🚀 View run glad-hill-136 at: https://wandb.ai/epistoteles/partial-model-merging/runs/jozzqxml
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231110_171503-jozzqxml/logs
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=0.5, epochs=100, lr=0.08, weight_decay=0.0005, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231110_171817-zf18w5qk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-yogurt-137
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/zf18w5qk
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:02:50
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇███████████
wandb:      test_loss █▅▃▂▂▂▂▁▁▂▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb:     train_loss █▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.8989
wandb:      test_loss 0.41519
wandb: train_accuracy 0.99826
wandb:     train_loss 0.00785
wandb: 
wandb: 🚀 View run daily-yogurt-137 at: https://wandb.ai/epistoteles/partial-model-merging/runs/zf18w5qk
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231110_171817-zf18w5qk/logs
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=0.25, epochs=100, lr=0.08, weight_decay=0.0005, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231110_172131-up36whdr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-planet-138
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/up36whdr
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:01:41
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▂▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█████████
wandb:      test_loss █▇▃▃▂▃▂▃▂▂▂▂▃▁▂▂▂▂▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:     train_loss █▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.8737
wandb:      test_loss 0.45456
wandb: train_accuracy 0.97938
wandb:     train_loss 0.06454
wandb: 
wandb: 🚀 View run efficient-planet-138 at: https://wandb.ai/epistoteles/partial-model-merging/runs/up36whdr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231110_172131-up36whdr/logs
Namespace(dataset='CIFAR10', model_type='VGG', size=11, batch_norm=True, 
width=0.25, epochs=100, lr=0.08, weight_decay=0.0005, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231110_172334-q76vth27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-tree-139
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/q76vth27
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:01:41
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▃▅▆▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇██▇████████████████
wandb:      test_loss █▆▄▃▃▂▂▂▃▂▃▁▁▂▁▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:     train_loss █▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.8684
wandb:      test_loss 0.46527
wandb: train_accuracy 0.97732
wandb:     train_loss 0.06908
wandb: 
wandb: 🚀 View run warm-tree-139 at: https://wandb.ai/epistoteles/partial-model-merging/runs/q76vth27
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231110_172334-q76vth27/logs
