-------------------SBATCH STATS-------------------
Total CPU cores:      6
Visible CPU cores:    3
Visible GPUs:         NVIDIA GeForce GTX 1060 6GB
--------------------------------------------------
/var/spool/slurmd/job00140/slurm_script: line 26: src/train.py: Permission denied
/var/spool/slurmd/job00140/slurm_script: line 27: src/train.py: Permission denied
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_163014-soa6x9vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-shape-226
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/soa6x9vt
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:00
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP3-2.0x-a
train_acc    0.99995
train_loss   0.0008151757215576557
test_acc     0.9906
test_loss    0.029379330202937128
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇█████████████████████████████████████
wandb:      test_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9906
wandb:      test_loss 0.02938
wandb: train_accuracy 0.99985
wandb:     train_loss 0.00155
wandb: 
wandb: 🚀 View run young-shape-226 at: https://wandb.ai/epistoteles/partial-model-merging/runs/soa6x9vt
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_163014-soa6x9vt/logs
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_163647-82zgbmsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-resonance-227
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/82zgbmsd
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:09
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP3-2.0x-b
train_acc    0.9999333333333333
train_loss   0.0008183330462391799
test_acc     0.9897
test_loss    0.030570070166140793
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆██████████████████████████████████████
wandb:      test_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9897
wandb:      test_loss 0.03057
wandb: train_accuracy 0.99987
wandb:     train_loss 0.00171
wandb: 
wandb: 🚀 View run leafy-resonance-227 at: https://wandb.ai/epistoteles/partial-model-merging/runs/82zgbmsd
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_163647-82zgbmsd/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_164327-3707mmcw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-cloud-228
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/3707mmcw
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:05
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP4-2.0x-a
train_acc    1.0
train_loss   0.00020123330814385553
test_acc     0.9912
test_loss    0.03363242968916893
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9912
wandb:      test_loss 0.03363
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00053
wandb: 
wandb: 🚀 View run neat-cloud-228 at: https://wandb.ai/epistoteles/partial-model-merging/runs/3707mmcw
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_164327-3707mmcw/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_165007-hji2elxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-fog-229
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/hji2elxw
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:12
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP4-2.0x-b
train_acc    0.9999833333333333
train_loss   0.00021828259329292147
test_acc     0.9907
test_loss    0.03442653156816959
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9907
wandb:      test_loss 0.03443
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00041
wandb: 
wandb: 🚀 View run pleasant-fog-229 at: https://wandb.ai/epistoteles/partial-model-merging/runs/hji2elxw
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_165007-hji2elxw/logs
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 260, in check_network_status
    self._loop_check_status(
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 216, in _loop_check_status
    local_handle = request()
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 795, in deliver_network_status
    return self._deliver_network_status(status)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 601, in _deliver_network_status
    return self._deliver_record(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 560, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
Namespace(dataset='MNIST', model_type='MLP', size=5, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_165650-mwz318e6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-rain-231
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/mwz318e6
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:33
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP5-2.0x-a
train_acc    0.9999833333333333
train_loss   0.0001374527249330034
test_acc     0.991
test_loss    0.04215614721179008
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.991
wandb:      test_loss 0.04216
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00027
wandb: 
wandb: 🚀 View run trim-rain-231 at: https://wandb.ai/epistoteles/partial-model-merging/runs/mwz318e6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_165650-mwz318e6/logs
Namespace(dataset='MNIST', model_type='MLP', size=5, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_170352-e4tiou3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sky-233
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/e4tiou3i
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:29
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP5-2.0x-b
train_acc    0.9999833333333333
train_loss   0.00013071820482461285
test_acc     0.9914
test_loss    0.03827211279422045
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁███████████████████████████████████████
wandb:      test_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9914
wandb:      test_loss 0.03827
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00027
wandb: 
wandb: 🚀 View run eager-sky-233 at: https://wandb.ai/epistoteles/partial-model-merging/runs/e4tiou3i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_170352-e4tiou3i/logs
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 278, in check_stop_status
    self._loop_check_status(
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 216, in _loop_check_status
    local_handle = request()
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 787, in deliver_stop_status
    return self._deliver_stop_status(status)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 585, in _deliver_stop_status
    return self._deliver_record(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 560, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
Namespace(dataset='MNIST', model_type='MLP', size=6, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_171051-wd24ial0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-surf-235
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/wd24ial0
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:33
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP6-2.0x-a
train_acc    0.9999833333333333
train_loss   0.00014126874433107635
test_acc     0.9915
test_loss    0.04440286308526993
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄██████████████████████████████████████
wandb:     train_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9915
wandb:      test_loss 0.0444
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00025
wandb: 
wandb: 🚀 View run solar-surf-235 at: https://wandb.ai/epistoteles/partial-model-merging/runs/wd24ial0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_171051-wd24ial0/logs
Namespace(dataset='MNIST', model_type='MLP', size=6, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_171754-o2o1t1n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-planet-237
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/o2o1t1n2
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:31
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP6-2.0x-b
train_acc    0.9999833333333333
train_loss   0.00012622711753162245
test_acc     0.99
test_loss    0.049035402946174145
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄██████████████████████████████████████
wandb:     train_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.99
wandb:      test_loss 0.04904
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00028
wandb: 
wandb: 🚀 View run young-planet-237 at: https://wandb.ai/epistoteles/partial-model-merging/runs/o2o1t1n2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_171754-o2o1t1n2/logs
Namespace(dataset='MNIST', model_type='MLP', size=7, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_172454-3g9w262g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-disco-239
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/3g9w262g
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:39
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP7-2.0x-a
train_acc    0.9999666666666667
train_loss   0.00021814125617917549
test_acc     0.9904
test_loss    0.04532481152564287
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▃█████████████████████████████████████
wandb:      test_loss ██▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▄▇████████████████████████████████████
wandb:     train_loss ██▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9904
wandb:      test_loss 0.04532
wandb: train_accuracy 0.99988
wandb:     train_loss 0.00061
wandb: 
wandb: 🚀 View run decent-disco-239 at: https://wandb.ai/epistoteles/partial-model-merging/runs/3g9w262g
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_172454-3g9w262g/logs
Namespace(dataset='MNIST', model_type='MLP', size=7, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_173202-o8l5pnsa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-vortex-241
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/o8l5pnsa
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:36
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP7-2.0x-b
train_acc    0.99995
train_loss   0.00024360671638229786
test_acc     0.9897
test_loss    0.05415641404688358
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁██████████████████████████████████████
wandb:      test_loss ██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▆█████████████████████████████████████
wandb:     train_loss ▇█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9897
wandb:      test_loss 0.05416
wandb: train_accuracy 0.99983
wandb:     train_loss 0.00071
wandb: 
wandb: 🚀 View run magic-vortex-241 at: https://wandb.ai/epistoteles/partial-model-merging/runs/o8l5pnsa
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_173202-o8l5pnsa/logs
Namespace(dataset='MNIST', model_type='MLP', size=8, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_173910-blewirme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-firebrand-243
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/blewirme
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:41
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP8-2.0x-a
train_acc    0.9999666666666667
train_loss   0.00020817902495764428
test_acc     0.9892
test_loss    0.05784456618130207
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▂▄▇████████████████████████████████████
wandb:      test_loss ██▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▆████████████████████████████████████
wandb:     train_loss ██▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9892
wandb:      test_loss 0.05784
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00036
wandb: 
wandb: 🚀 View run toasty-firebrand-243 at: https://wandb.ai/epistoteles/partial-model-merging/runs/blewirme
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_173910-blewirme/logs
Namespace(dataset='MNIST', model_type='MLP', size=8, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_174620-ripcko78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-thunder-245
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/ripcko78
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:37
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP8-2.0x-b
train_acc    0.09871666666666666
train_loss   nan
test_acc     0.098
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▂▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      test_loss █▇▄▁                                    
wandb: train_accuracy ▁▁▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ██▆▁                                    
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.098
wandb:      test_loss nan
wandb: train_accuracy 0.09872
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run helpful-thunder-245 at: https://wandb.ai/epistoteles/partial-model-merging/runs/ripcko78
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_174620-ripcko78/logs
Namespace(dataset='MNIST', model_type='MLP', size=9, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_175340-77wdahra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-oath-247
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/77wdahra
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:42
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP9-2.0x-a
train_acc    0.9999166666666667
train_loss   0.000364736576739233
test_acc     0.9894
test_loss    0.06138859167695045
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁▃▇███████████████████████████████████
wandb:      test_loss ███▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▇███████████████████████████████████
wandb:     train_loss ███▇▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9894
wandb:      test_loss 0.06139
wandb: train_accuracy 0.99983
wandb:     train_loss 0.00066
wandb: 
wandb: 🚀 View run warm-oath-247 at: https://wandb.ai/epistoteles/partial-model-merging/runs/77wdahra
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_175340-77wdahra/logs
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 278, in check_stop_status
    self._loop_check_status(
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 216, in _loop_check_status
    local_handle = request()
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 787, in deliver_stop_status
    return self._deliver_stop_status(status)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 585, in _deliver_stop_status
    return self._deliver_record(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 560, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
Namespace(dataset='MNIST', model_type='MLP', size=9, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_180053-zx462c9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-cherry-249
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/zx462c9s
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:39
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP9-2.0x-b
train_acc    0.09871666666666666
train_loss   nan
test_acc     0.098
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▆▆▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      test_loss ███▁                                    
wandb: train_accuracy ▂▂▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ▆▆█▁                                    
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.098
wandb:      test_loss nan
wandb: train_accuracy 0.09872
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run valiant-cherry-249 at: https://wandb.ai/epistoteles/partial-model-merging/runs/zx462c9s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_180053-zx462c9s/logs
Namespace(dataset='MNIST', model_type='MLP', size=10, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_180803-xxevrplw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-meadow-251
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/xxevrplw
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:42
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP10-2.0x-a
train_acc    0.09871666666666666
train_loss   nan
test_acc     0.098
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁▃▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      test_loss ███▆▂▁                                  
wandb: train_accuracy ▁▁▁▂▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ███▇▃▁                                  
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.098
wandb:      test_loss nan
wandb: train_accuracy 0.09872
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run upbeat-meadow-251 at: https://wandb.ai/epistoteles/partial-model-merging/runs/xxevrplw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_180803-xxevrplw/logs
Namespace(dataset='MNIST', model_type='MLP', size=10, batch_norm=False, 
width=2.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_181517-294i7h5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-silence-253
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/294i7h5c
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:51
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP10-2.0x-b
train_acc    0.9997833333333334
train_loss   0.0009896605178558579
test_acc     0.9875
test_loss    0.06593117415904999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁▃▆▃▇█████████████████████████████████
wandb:      test_loss ███▆▃▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▃▅▅▆▇████████████████████████████████
wandb:     train_loss ███▆▄▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9875
wandb:      test_loss 0.06593
wandb: train_accuracy 0.99938
wandb:     train_loss 0.00275
wandb: 
wandb: 🚀 View run vague-silence-253 at: https://wandb.ai/epistoteles/partial-model-merging/runs/294i7h5c
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_181517-294i7h5c/logs
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_182237-hq982m7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-serenity-255
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/hq982m7b
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:37
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP3-4.0x-a
train_acc    0.9999666666666667
train_loss   0.000627931862254627
test_acc     0.9913
test_loss    0.028939763270318507
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇█████████████████████████████████████
wandb:      test_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9913
wandb:      test_loss 0.02894
wandb: train_accuracy 0.99987
wandb:     train_loss 0.00132
wandb: 
wandb: 🚀 View run light-serenity-255 at: https://wandb.ai/epistoteles/partial-model-merging/runs/hq982m7b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_182237-hq982m7b/logs
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_182944-z9ya4trq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-haze-257
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/z9ya4trq
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:34
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP3-4.0x-b
train_acc    0.9999666666666667
train_loss   0.0006437964759243187
test_acc     0.9915
test_loss    0.02904287036508322
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇█████████████████████████████████████
wandb:      test_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9915
wandb:      test_loss 0.02904
wandb: train_accuracy 0.99998
wandb:     train_loss 0.0012
wandb: 
wandb: 🚀 View run honest-haze-257 at: https://wandb.ai/epistoteles/partial-model-merging/runs/z9ya4trq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_182944-z9ya4trq/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_183650-i9znahee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-wave-259
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/i9znahee
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:49
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP4-4.0x-a
train_acc    0.9999833333333333
train_loss   0.00016888725937557562
test_acc     0.9906
test_loss    0.03465712433680892
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9906
wandb:      test_loss 0.03466
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00036
wandb: 
wandb: 🚀 View run light-wave-259 at: https://wandb.ai/epistoteles/partial-model-merging/runs/i9znahee
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_183650-i9znahee/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_184409-xf7oc106
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-lion-261
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/xf7oc106
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:50
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP4-4.0x-b
train_acc    1.0
train_loss   0.00015747874076623702
test_acc     0.9916
test_loss    0.03574779126793146
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9916
wandb:      test_loss 0.03575
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00032
wandb: 
wandb: 🚀 View run silvery-lion-261 at: https://wandb.ai/epistoteles/partial-model-merging/runs/xf7oc106
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_184409-xf7oc106/logs
Namespace(dataset='MNIST', model_type='MLP', size=5, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_185134-5lwmhw06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-violet-263
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/5lwmhw06
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:01
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP5-4.0x-a
train_acc    0.9999833333333333
train_loss   0.0001376037391916422
test_acc     0.9913
test_loss    0.039040475711226465
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9913
wandb:      test_loss 0.03904
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00025
wandb: 
wandb: 🚀 View run decent-violet-263 at: https://wandb.ai/epistoteles/partial-model-merging/runs/5lwmhw06
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_185134-5lwmhw06/logs
Namespace(dataset='MNIST', model_type='MLP', size=5, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_185906-jgy1rj1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-flower-266
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/jgy1rj1i
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:06:59
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP5-4.0x-b
train_acc    1.0
train_loss   9.352455335829291e-05
test_acc     0.9914
test_loss    0.03732053730636835
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9914
wandb:      test_loss 0.03732
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00022
wandb: 
wandb: 🚀 View run dry-flower-266 at: https://wandb.ai/epistoteles/partial-model-merging/runs/jgy1rj1i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_185906-jgy1rj1i/logs
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 278, in check_stop_status
    self._loop_check_status(
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 216, in _loop_check_status
    local_handle = request()
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 787, in deliver_stop_status
    return self._deliver_stop_status(status)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 585, in _deliver_stop_status
    return self._deliver_record(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 560, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
Namespace(dataset='MNIST', model_type='MLP', size=6, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_190634-7y1uoccd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-lake-268
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/7y1uoccd
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:12
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP6-4.0x-a
train_acc    0.9999666666666667
train_loss   0.00011882907168304276
test_acc     0.9902
test_loss    0.049482261575758454
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▅██████████████████████████████████████
wandb:      test_loss █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃██████████████████████████████████████
wandb:     train_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9902
wandb:      test_loss 0.04948
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00023
wandb: 
wandb: 🚀 View run trim-lake-268 at: https://wandb.ai/epistoteles/partial-model-merging/runs/7y1uoccd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_190634-7y1uoccd/logs
Namespace(dataset='MNIST', model_type='MLP', size=6, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_191421-hc82z746
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sound-270
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/hc82z746
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:11
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP6-4.0x-b
train_acc    1.0
train_loss   7.332155611644945e-05
test_acc     0.9905
test_loss    0.05084014255553484
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▅██████████████████████████████████████
wandb:      test_loss █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃██████████████████████████████████████
wandb:     train_loss █▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9905
wandb:      test_loss 0.05084
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00018
wandb: 
wandb: 🚀 View run rural-sound-270 at: https://wandb.ai/epistoteles/partial-model-merging/runs/hc82z746
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_191421-hc82z746/logs
Namespace(dataset='MNIST', model_type='MLP', size=7, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_192201-p26zzoao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-wind-272
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/p26zzoao
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:36
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP7-4.0x-a
train_acc    0.9999833333333333
train_loss   0.00014301435236726927
test_acc     0.9897
test_loss    0.061524002254009245
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▂▄█████████████████████████████████████
wandb:      test_loss █▇▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▃▇████████████████████████████████████
wandb:     train_loss ██▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9897
wandb:      test_loss 0.06152
wandb: train_accuracy 0.99995
wandb:     train_loss 0.0004
wandb: 
wandb: 🚀 View run drawn-wind-272 at: https://wandb.ai/epistoteles/partial-model-merging/runs/p26zzoao
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_192201-p26zzoao/logs
Namespace(dataset='MNIST', model_type='MLP', size=7, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_193010-sxkgfi78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-shape-274
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/sxkgfi78
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:34
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP7-4.0x-b
train_acc    0.9999833333333333
train_loss   0.00011519936482121315
test_acc     0.9901
test_loss    0.056039486080408096
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▇█████████████████████████████████████
wandb:      test_loss ██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅█████████████████████████████████████
wandb:     train_loss ██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9901
wandb:      test_loss 0.05604
wandb: train_accuracy 0.99997
wandb:     train_loss 0.0002
wandb: 
wandb: 🚀 View run rose-shape-274 at: https://wandb.ai/epistoteles/partial-model-merging/runs/sxkgfi78
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_193010-sxkgfi78/logs
Namespace(dataset='MNIST', model_type='MLP', size=8, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_193824-gdye8kkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-paper-276
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/gdye8kkt
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:08:06
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP8-4.0x-a
train_acc    0.9999833333333333
train_loss   0.00013161466998402223
test_acc     0.9893
test_loss    0.05660929158329964
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▂▇█████████████████████████████████████
wandb:      test_loss █▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▆█████████████████████████████████████
wandb:     train_loss ██▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9893
wandb:      test_loss 0.05661
wandb: train_accuracy 0.99995
wandb:     train_loss 0.00028
wandb: 
wandb: 🚀 View run distinctive-paper-276 at: https://wandb.ai/epistoteles/partial-model-merging/runs/gdye8kkt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_193824-gdye8kkt/logs
Namespace(dataset='MNIST', model_type='MLP', size=8, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_194702-w4vr83pq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-bush-278
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/w4vr83pq
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:08:07
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP8-4.0x-b
train_acc    0.9998833333333333
train_loss   0.0005659368795022601
test_acc     0.9891
test_loss    0.055650569871068
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▃▁▁▂▄██████████████████████████████████
wandb:      test_loss █▇███▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▄▃▇█████████████████████████████████
wandb:     train_loss ▇▇█▇▅▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9891
wandb:      test_loss 0.05565
wandb: train_accuracy 0.9997
wandb:     train_loss 0.00156
wandb: 
wandb: 🚀 View run frosty-bush-278 at: https://wandb.ai/epistoteles/partial-model-merging/runs/w4vr83pq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_194702-w4vr83pq/logs
Namespace(dataset='MNIST', model_type='MLP', size=9, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_195538-wpzkqm5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-paper-281
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/wpzkqm5x
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:08:41
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP9-4.0x-a
train_acc    0.9999833333333333
train_loss   0.0001998225876983876
test_acc     0.9896
test_loss    0.06346487253904343
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▅▇████████████████████████████████████
wandb:      test_loss ██▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▆████████████████████████████████████
wandb:     train_loss ██▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9896
wandb:      test_loss 0.06346
wandb: train_accuracy 0.99995
wandb:     train_loss 0.0003
wandb: 
wandb: 🚀 View run vocal-paper-281 at: https://wandb.ai/epistoteles/partial-model-merging/runs/wpzkqm5x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_195538-wpzkqm5x/logs
Namespace(dataset='MNIST', model_type='MLP', size=9, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_200449-49hzdjj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-totem-283
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/49hzdjj7
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:08:40
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP9-4.0x-b
train_acc    0.9999833333333333
train_loss   0.00018082484093611128
test_acc     0.9908
test_loss    0.05039373822510242
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁▂▆███████████████████████████████████
wandb:      test_loss ███▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▂▅▇██████████████████████████████████
wandb:     train_loss ██▇▇▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9908
wandb:      test_loss 0.05039
wandb: train_accuracy 0.99992
wandb:     train_loss 0.00038
wandb: 
wandb: 🚀 View run glowing-totem-283 at: https://wandb.ai/epistoteles/partial-model-merging/runs/49hzdjj7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_200449-49hzdjj7/logs
Namespace(dataset='MNIST', model_type='MLP', size=10, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_201400-ywfr0v8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sponge-285
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/ywfr0v8a
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:08:53
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP10-4.0x-a
train_acc    0.09871666666666666
train_loss   nan
test_acc     0.098
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁█▄▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      test_loss ███▁█▃                                  
wandb: train_accuracy ▁▂▃█▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ███▁█▂                                  
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.098
wandb:      test_loss nan
wandb: train_accuracy 0.09872
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run peachy-sponge-285 at: https://wandb.ai/epistoteles/partial-model-merging/runs/ywfr0v8a
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_201400-ywfr0v8a/logs
Namespace(dataset='MNIST', model_type='MLP', size=10, batch_norm=False, 
width=4.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_202325-p8ex7dn0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-rain-288
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/p8ex7dn0
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:08:56
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP10-4.0x-b
train_acc    0.11486666666666667
train_loss   nan
test_acc     0.1123
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▂▂▂▂▁▂▂▂█▆▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      test_loss ▁▁▁▁▁▁▁▁▁▁█                             
wandb: train_accuracy ▁▁▂▁█▁▁▁▃▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ▁▁▁▁▁▁▁▁▁▁█                             
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.1123
wandb:      test_loss nan
wandb: train_accuracy 0.11567
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run usual-rain-288 at: https://wandb.ai/epistoteles/partial-model-merging/runs/p8ex7dn0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_202325-p8ex7dn0/logs
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_203300-iuczospc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-pine-290
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/iuczospc
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:20
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP3-8.0x-a
train_acc    0.9999666666666667
train_loss   0.0005529083338236281
test_acc     0.9914
test_loss    0.02810792177915573
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇▇████████████████████████████████████
wandb:      test_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9914
wandb:      test_loss 0.02811
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00101
wandb: 
wandb: 🚀 View run dandy-pine-290 at: https://wandb.ai/epistoteles/partial-model-merging/runs/iuczospc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_203300-iuczospc/logs
Namespace(dataset='MNIST', model_type='MLP', size=3, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_204049-2bywop86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-smoke-292
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/2bywop86
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:07:17
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP3-8.0x-b
train_acc    0.9999666666666667
train_loss   0.0005306802857376169
test_acc     0.9909
test_loss    0.030144906230270864
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇█████████████████████████████████████
wandb:      test_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9909
wandb:      test_loss 0.03014
wandb: train_accuracy 0.99992
wandb:     train_loss 0.0011
wandb: 
wandb: 🚀 View run vivid-smoke-292 at: https://wandb.ai/epistoteles/partial-model-merging/runs/2bywop86
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_204049-2bywop86/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_204837-anyqfwz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-durian-294
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/anyqfwz2
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:09:28
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP4-8.0x-a
train_acc    1.0
train_loss   0.00012210702461743495
test_acc     0.9918
test_loss    0.0323605764657259
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇▇█████████████████████████████████████
wandb:      test_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9918
wandb:      test_loss 0.03236
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00027
wandb: 
wandb: 🚀 View run whole-durian-294 at: https://wandb.ai/epistoteles/partial-model-merging/runs/anyqfwz2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_204837-anyqfwz2/logs
Namespace(dataset='MNIST', model_type='MLP', size=4, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_205838-a8n8owyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sun-296
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/a8n8owyl
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:09:31
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP4-8.0x-b
train_acc    0.9999833333333333
train_loss   0.00014317567577866916
test_acc     0.9917
test_loss    0.03001112025231123
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▆▇█████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9917
wandb:      test_loss 0.03001
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00024
wandb: 
wandb: 🚀 View run restful-sun-296 at: https://wandb.ai/epistoteles/partial-model-merging/runs/a8n8owyl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_205838-a8n8owyl/logs
Namespace(dataset='MNIST', model_type='MLP', size=5, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_210840-w4lffjpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sun-299
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/w4lffjpi
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:13:12
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP5-8.0x-a
train_acc    1.0
train_loss   6.589347854060179e-05
test_acc     0.9921
test_loss    0.03628974985331297
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9921
wandb:      test_loss 0.03629
wandb: train_accuracy 1.0
wandb:     train_loss 0.0001
wandb: 
wandb: 🚀 View run whole-sun-299 at: https://wandb.ai/epistoteles/partial-model-merging/runs/w4lffjpi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_210840-w4lffjpi/logs
Namespace(dataset='MNIST', model_type='MLP', size=5, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_212224-irw81e3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-yogurt-302
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/irw81e3l
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:13:12
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP5-8.0x-b
train_acc    0.9999833333333333
train_loss   0.00010482866553805555
test_acc     0.9912
test_loss    0.037499196268618105
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▇██████████████████████████████████████
wandb:     train_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9912
wandb:      test_loss 0.0375
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00016
wandb: 
wandb: 🚀 View run comic-yogurt-302 at: https://wandb.ai/epistoteles/partial-model-merging/runs/irw81e3l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_212224-irw81e3l/logs
Namespace(dataset='MNIST', model_type='MLP', size=6, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_213608-bz46p05k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sea-305
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/bz46p05k
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:16:50
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP6-8.0x-a
train_acc    0.9999666666666667
train_loss   8.811738659157224e-05
test_acc     0.9916
test_loss    0.044689312018454073
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▅██████████████████████████████████████
wandb:     train_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9916
wandb:      test_loss 0.04469
wandb: train_accuracy 0.99997
wandb:     train_loss 0.00014
wandb: 
wandb: 🚀 View run upbeat-sea-305 at: https://wandb.ai/epistoteles/partial-model-merging/runs/bz46p05k
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_213608-bz46p05k/logs
Namespace(dataset='MNIST', model_type='MLP', size=6, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_215333-frrkc10u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-plasma-308
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/frrkc10u
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:16:59
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP6-8.0x-b
train_acc    0.9999833333333333
train_loss   8.615473307145294e-05
test_acc     0.9912
test_loss    0.044065835792571305
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▇██████████████████████████████████████
wandb:      test_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▆██████████████████████████████████████
wandb:     train_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9912
wandb:      test_loss 0.04407
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00018
wandb: 
wandb: 🚀 View run amber-plasma-308 at: https://wandb.ai/epistoteles/partial-model-merging/runs/frrkc10u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_215333-frrkc10u/logs
Namespace(dataset='MNIST', model_type='MLP', size=7, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_221105-aqwr2jf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-serenity-312
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/aqwr2jf9
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:20:40
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP7-8.0x-a
train_acc    1.0
train_loss   4.908016794615833e-05
test_acc     0.9909
test_loss    0.046706953831017015
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄██████████████████████████████████████
wandb:      test_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂██████████████████████████████████████
wandb:     train_loss █▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9909
wandb:      test_loss 0.04671
wandb: train_accuracy 0.99998
wandb:     train_loss 0.00012
wandb: 
wandb: 🚀 View run deft-serenity-312 at: https://wandb.ai/epistoteles/partial-model-merging/runs/aqwr2jf9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_221105-aqwr2jf9/logs
Namespace(dataset='MNIST', model_type='MLP', size=7, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_223219-jc1dysdb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-plasma-315
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/jc1dysdb
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:20:41
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP7-8.0x-b
train_acc    1.0
train_loss   4.053930817159805e-05
test_acc     0.9912
test_loss    0.044550963677465916
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▃██████████████████████████████████████
wandb:      test_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂██████████████████████████████████████
wandb:     train_loss ██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9912
wandb:      test_loss 0.04455
wandb: train_accuracy 1.0
wandb:     train_loss 8e-05
wandb: 
wandb: 🚀 View run comfy-plasma-315 at: https://wandb.ai/epistoteles/partial-model-merging/runs/jc1dysdb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_223219-jc1dysdb/logs
Namespace(dataset='MNIST', model_type='MLP', size=8, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_225333-gujrh2ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-star-319
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/gujrh2ya
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:24:36
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP8-8.0x-a
train_acc    1.0
train_loss   2.6286531889733546e-05
test_acc     0.9904
test_loss    0.0546979758888483
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▄██████████████████████████████████████
wandb:      test_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂██████████████████████████████████████
wandb:     train_loss █▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9904
wandb:      test_loss 0.0547
wandb: train_accuracy 0.99998
wandb:     train_loss 7e-05
wandb: 
wandb: 🚀 View run driven-star-319 at: https://wandb.ai/epistoteles/partial-model-merging/runs/gujrh2ya
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_225333-gujrh2ya/logs
Namespace(dataset='MNIST', model_type='MLP', size=8, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_231843-rb8jngd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-glade-324
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/rb8jngd0
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:24:33
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP8-8.0x-b
train_acc    0.9999666666666667
train_loss   0.00014096451844428277
test_acc     0.9901
test_loss    0.05083196442574263
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▃▇████████████████████████████████████
wandb:      test_loss ██▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▅████████████████████████████████████
wandb:     train_loss ██▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9901
wandb:      test_loss 0.05083
wandb: train_accuracy 0.99992
wandb:     train_loss 0.00032
wandb: 
wandb: 🚀 View run effortless-glade-324 at: https://wandb.ai/epistoteles/partial-model-merging/runs/rb8jngd0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_231843-rb8jngd0/logs
Namespace(dataset='MNIST', model_type='MLP', size=9, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231126_234350-hzfdod1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-dragon-328
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/hzfdod1k
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:26:05
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP9-8.0x-a
train_acc    0.09871666666666666
train_loss   nan
test_acc     0.098
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▂▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      test_loss ▇▇█▃▁                                   
wandb: train_accuracy ▁▁▃▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ██▆▃▁                                   
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.098
wandb:      test_loss nan
wandb: train_accuracy 0.09872
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run earnest-dragon-328 at: https://wandb.ai/epistoteles/partial-model-merging/runs/hzfdod1k
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231126_234350-hzfdod1k/logs
Namespace(dataset='MNIST', model_type='MLP', size=9, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_001032-203ujmr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-microwave-332
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/203ujmr3
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:28:17
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP9-8.0x-b
train_acc    0.9999666666666667
train_loss   0.0002778742538187847
test_acc     0.9899
test_loss    0.06366260554641485
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁▁▁▁▁▁▁▁▃▇████████████████████████████
wandb:      test_loss ██████████▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▁▁▁▁▁▁▃▅▇███████████████████████████
wandb:     train_loss ██████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.9899
wandb:      test_loss 0.06366
wandb: train_accuracy 0.9998
wandb:     train_loss 0.00079
wandb: 
wandb: 🚀 View run curious-microwave-332 at: https://wandb.ai/epistoteles/partial-model-merging/runs/203ujmr3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231127_001032-203ujmr3/logs
Namespace(dataset='MNIST', model_type='MLP', size=10, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='a', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_003923-aamwns17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sun-336
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/aamwns17
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:31:35
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP10-8.0x-a
train_acc    0.9999333333333333
train_loss   0.0003859807303645842
test_acc     0.99
test_loss    0.06362596452236176
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▁▃▂▁▅▇████████████████████████████████
wandb:      test_loss ███▆▆█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▂▃▄▆████████████████████████████████
wandb:     train_loss ███▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.99
wandb:      test_loss 0.06363
wandb: train_accuracy 0.99988
wandb:     train_loss 0.00097
wandb: 
wandb: 🚀 View run prime-sun-336 at: https://wandb.ai/epistoteles/partial-model-merging/runs/aamwns17
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231127_003923-aamwns17/logs
Namespace(dataset='MNIST', model_type='MLP', size=10, batch_norm=False, 
width=8.0, epochs=100, lr=0.2, weight_decay=0.0, variant='b', wandb=True, 
test=True, checkpoint_midway=False)
wandb: Currently logged in as: epistoteles. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /home/korbinian/Documents/partial-model-merging/wandb/run-20231127_011134-bgu7od6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-lion-337
wandb: ⭐️ View project at https://wandb.ai/epistoteles/partial-model-merging
wandb: 🚀 View run at https://wandb.ai/epistoteles/partial-model-merging/runs/bgu7od6s
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:28:49
/home/korbinian/Documents/partial-model-merging/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
📥 Accuracies and losses saved for MNIST-MLP10-8.0x-b
train_acc    0.09871666666666666
train_loss   nan
test_acc     0.098
test_loss    nan
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:  test_accuracy ▁▁▅█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      test_loss ██▄▁                                    
wandb: train_accuracy ▁▁▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ██▅▁                                    
wandb: 
wandb: Run summary:
wandb:          epoch 99
wandb:  learning_rate 0.0
wandb:  test_accuracy 0.098
wandb:      test_loss nan
wandb: train_accuracy 0.09872
wandb:     train_loss nan
wandb: 
wandb: 🚀 View run faithful-lion-337 at: https://wandb.ai/epistoteles/partial-model-merging/runs/bgu7od6s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231127_011134-bgu7od6s/logs
